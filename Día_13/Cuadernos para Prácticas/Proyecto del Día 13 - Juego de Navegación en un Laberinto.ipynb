{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bf2362",
   "metadata": {},
   "source": [
    "## Proyecto del Día 13 - Juego de Navegación en un Laberinto\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un entorno de laberinto simple y aplicar un algoritmo de **Aprendizaje por Refuerzo** para enseñar a una IA a navegar desde un punto inicial hasta un objetivo.\n",
    "\n",
    "Dada la naturaleza de este proyecto, considero que el algoritmo más adecuado para este tipo de probleas es **Q-Learning**, por su facilidad de implelentación y comprensión, su estabilidad y su relación entre la exploración y la explotación.\n",
    "\n",
    "Por esa razón te propongo resolverlo usando ese algoritmo, aunque dejo a tu criterio si quieres resolverlo con otro algoritmo de tu elección. Siempre estaré a favor de que investigues, y expandas las habilidades propuestas por tu cuenta.\n",
    "\n",
    "### Descripción del Laberinto:\n",
    "\n",
    "El laberinto se representa como una matriz de dos dimensiones, donde cada elemento puede ser:\n",
    "+ un camino libre (0)\n",
    "+ un obstáculo (1)\n",
    "+ el objetivo (G)\n",
    "\n",
    "La tarea es desarrollar un agente que pueda aprender a encontrar el camino desde un punto de inicio hasta el objetivo evitando obstáculos.\n",
    "\n",
    "\n",
    "### Creación del Laberinto\n",
    "\n",
    "Debido a que el desafío de hoy es bastante complejo, y que el objetivo final no se trata de que sepas desarrollar laberintos, sino sistemas para resolverlos, voy a facilitar la tarea entregando en este cuaderno el código para generar nuestros laberintos.\n",
    "\n",
    "Tu parte será la siguiente, que es diseñar y entrenar un modelo de Q-Learning para resolver el laberinto de la manera mpas eficiente, y luego mostrar una visualización sobre cómo lo ha hecho.\n",
    "\n",
    "Te deseo toda la suerte del mundo, y sobre todo, que te diviertas de a montones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7ecc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías necesarias para todo el ejercicio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6370346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el laberinto\n",
    "def crear_laberinto(tamanio, porcentaje_paredes=20, inicio=(0, 0), meta=None):\n",
    "    laberinto = np.zeros((tamanio, tamanio)) #inicializo laberinto en con ceros\n",
    "    numero_paredes = int((tamanio * tamanio) * porcentaje_paredes / 100) #determino la cantidad de paredes que habran\n",
    "    \n",
    "    # Ubicar paredes\n",
    "    for pared in range(numero_paredes):\n",
    "        x, y = random.randint(0, tamanio-1), random.randint(0, tamanio-1)\n",
    "        \n",
    "        # Cuidar que inicio y meta no sean paredes\n",
    "        if (x, y) != inicio and (meta is None or (x, y) != meta):\n",
    "            laberinto[x, y] = 1\n",
    "            \n",
    "    # Ubicar la meta\n",
    "    if meta:\n",
    "        laberinto[meta] = 9  # Representa la meta con 9\n",
    "    else:\n",
    "        # Ubicar la meta aleatoriamente si no está especificado\n",
    "        while True:\n",
    "            x, y = random.randint(0, tamanio-1), random.randint(0, tamanio-1)\n",
    "            if laberinto[x, y] == 0 and (x, y) != inicio:\n",
    "                laberinto[x, y] = 9\n",
    "                break\n",
    "    \n",
    "    return laberinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c648cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para visualizar el laberinto\n",
    "def ver_laberinto(laberinto):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(laberinto, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e052cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de crear y mostrar laberintos\n",
    "laberinto = crear_laberinto(10, 20, inicio=(0, 0), meta=(9, 9))\n",
    "ver_laberinto(laberinto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f986ed5",
   "metadata": {},
   "source": [
    "### Ahora te toca a ti\n",
    "\n",
    "Lo que sigue es implementar todo el código para que un algoritmo de Q-Learning encuentre la manera más eficiente de llegar a la meta. Voy a dejarte los pasos que considero que son los necesarios para lograrlo\n",
    "\n",
    "##### 1. Parámetros para el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234853df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensiones = (laberinto.shape[0], laberinto.shape[1])\n",
    "estado_inicial = (0,0)\n",
    "movimientos = [(0,1),(0,-1),(1,0),(-1,0)] #Derecha, Izquierda, Abajo, Arriba\n",
    "num_estados = dimensiones[0] * dimensiones[1]\n",
    "num_acciones = len(movimientos)\n",
    "estado_final = ()\n",
    "obstaculos = []\n",
    "for i in range(len(laberinto)):\n",
    "    for j in range(len(laberinto[i])):\n",
    "        if laberinto[i][j] == 9:\n",
    "            estado_final = (i,j)\n",
    "        if laberinto[i][j] == 1:\n",
    "            obstaculos.append((i,j))\n",
    "\n",
    "Q = np.zeros((num_estados, num_acciones))\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125709aa",
   "metadata": {},
   "source": [
    "##### 2. Función para elegir acciones equilibrando entre explotación y exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbd3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.2\n",
    "episodios = 100\n",
    "\n",
    "def estado_a_indice(estado):\n",
    "    return estado[0] * dimensiones[1] + estado[1]\n",
    "\n",
    "def elegir_accion(estado):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.choice(range(num_acciones))\n",
    "    else:\n",
    "        return np.argmax(Q[estado_a_indice(estado)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a6550",
   "metadata": {},
   "source": [
    "##### 3. Función para simular la acción en el laberinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f719b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_accion(estado, accion_idx):\n",
    "    accion = movimientos[accion_idx]\n",
    "    nuevo_estado = tuple(np.add(estado, accion) % dimensiones)\n",
    "\n",
    "    if nuevo_estado == obstaculos or nuevo_estado == estado:\n",
    "        return estado, -100, False\n",
    "\n",
    "    if nuevo_estado == estado_final:\n",
    "        return nuevo_estado, 100, True\n",
    "    \n",
    "    return nuevo_estado, -1, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3dc48",
   "metadata": {},
   "source": [
    "##### 4. Función principal para ejecutar el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee5259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episodio in range(episodios):\n",
    "    estado = estado_inicial\n",
    "    terminado = False\n",
    "\n",
    "    while not terminado:\n",
    "        idx_estado = estado_a_indice(estado)\n",
    "        accion_idx = elegir_accion(estado)\n",
    "        nuevo_estado, recompensa, terminado = aplicar_accion(estado, accion_idx)\n",
    "        idx_nuevo_estado = estado_a_indice(nuevo_estado)\n",
    "\n",
    "        Q[idx_estado, accion_idx] = Q[idx_estado, accion_idx] + alpha * (recompensa + gamma * np.max(Q[idx_nuevo_estado]) - Q[idx_estado, accion_idx])\n",
    "        \n",
    "        estado = nuevo_estado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac97336",
   "metadata": {},
   "source": [
    "##### 5. Función para convertir coordenadas a índice lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5311d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politica = np.zeros(dimensiones, dtype=int)\n",
    "politica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f0d38",
   "metadata": {},
   "source": [
    "##### 6. Iniciar el laberinto y configurar el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2355b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dimensiones[0]):\n",
    "    for j in range(dimensiones[1]):\n",
    "        estado = (i,j)\n",
    "        idx_estado = estado_a_indice(estado)\n",
    "        mejor_accion = np.argmax(Q[idx_estado])\n",
    "        politica[i, j] = mejor_accion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf32a0",
   "metadata": {},
   "source": [
    "##### 7. Función para mostrar el aprendizaje del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42f818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Política aprendida (0: arriba, 1: abajo, 2: izquierda, 3: derecha)\n",
      "[[3 1 2 0 3 0 3 3 3 3]\n",
      " [3 0 0 3 0 0 3 1 1 0]\n",
      " [2 1 1 3 1 2 2 3 0 0]\n",
      " [3 0 1 1 1 1 1 1 0 0]\n",
      " [0 0 0 2 0 0 0 0 3 0]\n",
      " [2 0 0 2 3 0 0 3 0 0]\n",
      " [3 2 0 2 3 0 3 1 1 0]\n",
      " [2 2 0 3 2 1 0 0 0 3]\n",
      " [1 3 0 0 2 0 2 0 0 2]\n",
      " [1 1 1 1 3 1 3 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Política aprendida (0: arriba, 1: abajo, 2: izquierda, 3: derecha)\")\n",
    "print(politica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cb8db",
   "metadata": {},
   "source": [
    "##### 8. Visualizar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
